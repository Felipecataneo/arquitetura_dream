# ==============================================================================
#           SISTEMA DREAM V6.9: FRAMEWORK COGNITIVO COM VALIDA√á√ÉO ATIVA
#               Implementa auto-corre√ß√£o atrav√©s de valida√ß√£o de premissas
#               Resposta ao paper da Apple sobre "Illusion of Thinking"
# ==============================================================================

import json
import logging
import re
import time
from dataclasses import dataclass, field
from enum import Enum
from typing import Any, Dict, List, Optional, Union, Tuple
import math
import hashlib
from collections import defaultdict

# --- CONFIGURA√á√ÉO ---
try:
    import ollama
    OLLAMA_AVAILABLE = True
except ImportError:
    OLLAMA_AVAILABLE = False

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')

# --- N√çVEIS DE COMPLEXIDADE ---
class ComplexityLevel(Enum):
    TRIVIAL = 1
    BASIC = 2
    INTERMEDIATE = 3
    ADVANCED = 4
    EXPERT = 5

# --- TIPOS DE INCERTEZA ---
class UncertaintyType(Enum):
    FACTUAL = "factual"           # Incerteza sobre fatos
    CONCEPTUAL = "conceptual"     # Incerteza sobre conceitos
    RELATIONAL = "relational"     # Incerteza sobre rela√ß√µes
    PROCEDURAL = "procedural"     # Incerteza sobre m√©todos

# --- ESTRAT√âGIAS DE RACIOC√çNIO ---
class ReasoningStrategy(Enum):
    NEURAL_INTUITIVE = "neural_intuitive"
    VALIDATED_REASONING = "validated_reasoning"
    SELF_CORRECTING_ANALYSIS = "self_correcting_analysis"
    PREMISE_DRIVEN_SYNTHESIS = "premise_driven_synthesis"
    CONCEPTUAL_SYNTHESIS = "conceptual_synthesis"
    RIDDLE_ANALYSIS = "riddle_analysis"
    MATHEMATICAL_DECOMPOSITION = "mathematical_decomposition"
    HYBRID_ALGORITHMIC = "hybrid_algorithmic"

# --- VALIDADOR DE PREMISSAS ---
class PremiseValidator:
    def __init__(self, ollama_model: str):
        self.ollama_model = ollama_model
        self.confidence_threshold = 0.6
        self.validation_cache = {}
    
    def validate_premise(self, premise: str, context: Dict) -> Dict:
        """Valida uma premissa e retorna confian√ßa + sugest√µes de corre√ß√£o"""
        cache_key = hashlib.md5(premise.encode()).hexdigest()
        if cache_key in self.validation_cache:
            return self.validation_cache[cache_key]
        
        if not OLLAMA_AVAILABLE:
            return {"confidence": 0.5, "needs_validation": True, "validation_plan": []}
        
        prompt = f"""
        Voc√™ √© um validador de conhecimento cient√≠fico. Avalie a seguinte afirma√ß√£o:
        
        AFIRMA√á√ÉO: "{premise}"
        CONTEXTO: {context}
        
        Responda em JSON com:
        - "confidence": float entre 0 e 1 (sua confian√ßa na veracidade)
        - "uncertainty_type": "factual", "conceptual", "relational", ou "procedural"
        - "critical_assumptions": lista de suposi√ß√µes cr√≠ticas
        - "validation_queries": lista de perguntas espec√≠ficas para validar
        - "correction_hints": sugest√µes se a afirma√ß√£o parecer incorreta
        - "needs_external_validation": true/false
        
        Seja honesto sobre limita√ß√µes do seu conhecimento.
        """
        
        try:
            response = ollama.chat(
                model=self.ollama_model,
                messages=[{'role': 'user', 'content': prompt}],
                format='json',
                options={'temperature': 0.2}
            )
            
            result = json.loads(response['message']['content'])
            result['needs_validation'] = result.get('confidence', 0) < self.confidence_threshold
            
            self.validation_cache[cache_key] = result
            return result
            
        except Exception as e:
            logging.error(f"Erro na valida√ß√£o de premissa: {e}")
            return {
                "confidence": 0.3,
                "uncertainty_type": "factual",
                "needs_validation": True,
                "validation_plan": [f"Verificar: {premise}"]
            }

# --- SISTEMA DE METACOGNI√á√ÉO AVAN√áADO ---
@dataclass
class AdvancedMetaCognitionState:
    # Estados b√°sicos
    current_strategy: ReasoningStrategy = ReasoningStrategy.NEURAL_INTUITIVE
    confidence: float = 0.0
    reasoning_trace: List[str] = field(default_factory=list)
    uncertainty_sources: List[str] = field(default_factory=list)
    complexity_level: ComplexityLevel = ComplexityLevel.TRIVIAL
    
    # Estados avan√ßados
    premise_validations: Dict[str, Dict] = field(default_factory=dict)
    knowledge_gaps: List[str] = field(default_factory=list)
    correction_attempts: int = 0
    max_corrections: int = 3
    
    # M√©tricas de desempenho
    decision_time: float = 0.0
    validation_time: float = 0.0
    total_premises_checked: int = 0
    high_confidence_premises: int = 0
    
    # Controle de fluxo
    validation_enabled: bool = True
    auto_correction_enabled: bool = True
    domain: str = "unknown"
    success: bool = False

# --- ANALISADOR DE CAUSA RAIZ APRIMORADO ---
class EnhancedRootCauseAnalyzer:
    def __init__(self, ollama_model: str):
        self.ollama_model = ollama_model
        self.premise_validator = PremiseValidator(ollama_model)
    
    def analyze_with_5whys(self, problem: str) -> Optional[Dict]:
        """An√°lise de 5 porqu√™s com valida√ß√£o de premissas"""
        if not OLLAMA_AVAILABLE:
            return None
        
        prompt = f"""
        Voc√™ √© um especialista em an√°lise de causa raiz. Analise a pergunta para descobrir:
        1. A inten√ß√£o fundamental (5 porqu√™s)
        2. Os conceitos-chave mencionados
        3. As premissas impl√≠citas na pergunta
        
        PERGUNTA: "{problem}"
        
        Responda em JSON com:
        - "why_chain": lista de objetos {{why: "pergunta", because: "resposta"}}
        - "root_cause": necessidade fundamental
        - "key_concepts": lista de conceitos principais
        - "implicit_premises": lista de premissas que a pergunta assume
        - "knowledge_requirements": tipos de conhecimento necess√°rios
        """
        
        try:
            response = ollama.chat(
                model=self.ollama_model,
                messages=[{'role': 'user', 'content': prompt}],
                format='json',
                options={'temperature': 0.3}
            )
            
            result = json.loads(response['message']['content'])
            
            # Validar premissas identificadas
            if 'implicit_premises' in result:
                validated_premises = {}
                for premise in result['implicit_premises']:
                    validation = self.premise_validator.validate_premise(
                        premise, {"problem": problem}
                    )
                    validated_premises[premise] = validation
                
                result['premise_validations'] = validated_premises
            
            return {"success": True, **result}
            
        except Exception as e:
            logging.error(f"Erro na an√°lise dos 5 Porqu√™s: {e}")
            return {"success": False, "error": str(e)}

# --- CLASSES AUXILIARES ---
class AgentMemory:
    def __init__(self):
        self._knowledge: Dict[str, List[str]] = {}
        self._strategy_success: Dict[str, Dict[str, int]] = {}
    
    def add_learning(self, domain: str, learning: str):
        if domain not in self._knowledge:
            self._knowledge[domain] = []
        if learning not in self._knowledge[domain]:
            self._knowledge[domain].append(learning)
    
    def get_learnings(self, domain: str) -> List[str]:
        return self._knowledge.get(domain, [])
    
    def record_performance(self, domain: str, strategy: str, success: bool):
        if domain not in self._strategy_success:
            self._strategy_success[domain] = {}
        current = self._strategy_success[domain].get(strategy, 0)
        self._strategy_success[domain][strategy] = current + (1 if success else 0)

class DomainComplexityAnalyzer:
    def __init__(self):
        self.domain_keywords = {
            "academic_query": [
                "explain the theory", "explique a teoria", "teorema", "theorem", 
                "hilbert", "bifurca√ß√£o", "bifurcation", "relatividade", "qu√¢ntica",
                "geometrica", "problema de hilbert"
            ],
            "riddle_logic": ["which weighs more", "riddle", "charada"],
            "mathematical": ["equa√ß√£o", "resolver", "n√∫mero", "divisor"],
            "general": []
        }
    
    def analyze_problem(self, problem: str) -> Dict:
        problem_lower = problem.lower()
        
        # Detectar dom√≠nio
        if any(kw in problem_lower for kw in self.domain_keywords["academic_query"]):
            domain = "academic_query"
            complexity = ComplexityLevel.EXPERT
        elif any(kw in problem_lower for kw in self.domain_keywords["riddle_logic"]):
            domain = "riddle_logic"
            complexity = ComplexityLevel.INTERMEDIATE
        elif any(kw in problem_lower for kw in self.domain_keywords["mathematical"]):
            domain = "mathematical"
            complexity = ComplexityLevel.ADVANCED
        else:
            domain = "general"
            complexity = ComplexityLevel.BASIC
        
        return {
            "domain": domain,
            "complexity_level": complexity,
            "context": {"original_problem": problem}
        }

# --- SISTEMA DREAM PRINCIPAL APRIMORADO ---
class DreamSystemV69:
    def __init__(self, ollama_model: str = 'gemma3', enable_validation: bool = True):
        self.ollama_model = ollama_model
        self.enable_validation = enable_validation
        
        # Componentes principais
        self.memory = AgentMemory()
        self.domain_analyzer = DomainComplexityAnalyzer()
        self.root_cause_analyzer = EnhancedRootCauseAnalyzer(ollama_model)
        self.premise_validator = PremiseValidator(ollama_model)
        
        # Estado e controle
        self.ollama_available = OLLAMA_AVAILABLE and self._check_ollama_connection()
        self.meta_state = AdvancedMetaCognitionState()
    
    def _check_ollama_connection(self) -> bool:
        if not OLLAMA_AVAILABLE:
            logging.warning("Ollama n√£o instalado.")
            return False
        try:
            ollama.show(self.ollama_model)
            logging.info("Ollama e modelo OK.")
            return True
        except Exception as e:
            logging.warning(f"Ollama n√£o dispon√≠vel: {e}")
            return False
    
    def solve_problem(self, problem: str) -> Dict:
        """Solu√ß√£o de problemas com valida√ß√£o ativa de premissas"""
        start_time = time.time()
        self.meta_state = AdvancedMetaCognitionState()
        self.meta_state.validation_enabled = self.enable_validation
        
        # An√°lise inicial
        analysis = self.domain_analyzer.analyze_problem(problem)
        self.meta_state.domain = analysis["domain"]
        self.meta_state.complexity_level = analysis["complexity_level"]
        
        self.meta_state.reasoning_trace.append(
            f"AN√ÅLISE INICIAL: Dom√≠nio={analysis['domain']}, Complexidade={analysis['complexity_level'].name}"
        )
        
        # An√°lise de causa raiz com valida√ß√£o
        validation_start = time.time()
        whys_analysis = self.root_cause_analyzer.analyze_with_5whys(problem)
        
        if whys_analysis and whys_analysis.get("success"):
            self.meta_state.reasoning_trace.append("AN√ÅLISE DE INTEN√á√ÉO: Causa raiz e premissas identificadas")
            
            # Processar valida√ß√µes de premissas
            if 'premise_validations' in whys_analysis:
                self.meta_state.premise_validations = whys_analysis['premise_validations']
                self._process_premise_validations()
            
            analysis['context'].update({
                'root_cause': whys_analysis.get('root_cause'),
                'key_concepts': whys_analysis.get('key_concepts', []),
                'knowledge_requirements': whys_analysis.get('knowledge_requirements', [])
            })
        
        self.meta_state.validation_time = time.time() - validation_start
        
        # Escolha e execu√ß√£o da estrat√©gia
        strategy = self._choose_strategy_with_validation(analysis)
        self.meta_state.current_strategy = strategy
        
        solution = self._execute_strategy_with_validation(problem, strategy, analysis)
        
        # Auto-corre√ß√£o se necess√°rio
        if self._needs_correction(solution) and self.meta_state.auto_correction_enabled:
            solution = self._attempt_self_correction(problem, solution, analysis)
        
        # Finaliza√ß√£o
        self.meta_state.decision_time = time.time() - start_time
        self.meta_state.success = not self._is_failure(solution)
        
        return {
            "solution": solution,
            "meta_state": self.meta_state,
            "analysis": analysis,
            "success": self.meta_state.success
        }
    
    def _process_premise_validations(self):
        """Processa valida√ß√µes de premissas e identifica gaps de conhecimento"""
        for premise, validation in self.meta_state.premise_validations.items():
            self.meta_state.total_premises_checked += 1
            
            confidence = validation.get('confidence', 0)
            if confidence > 0.8:
                self.meta_state.high_confidence_premises += 1
            
            if validation.get('needs_validation', False):
                self.meta_state.knowledge_gaps.append(premise)
                self.meta_state.reasoning_trace.append(
                    f"VALIDA√á√ÉO: Premissa incerta identificada: {premise[:50]}..."
                )
            
            if validation.get('needs_external_validation', False):
                self.meta_state.uncertainty_sources.append(
                    f"Premissa requer valida√ß√£o externa: {premise}"
                )
    
    def _choose_strategy_with_validation(self, analysis: Dict) -> ReasoningStrategy:
        """Escolhe estrat√©gia considerando necessidades de valida√ß√£o"""
        domain = analysis["domain"]
        complexity = analysis["complexity_level"]
        
        # Se h√° muitas premissas incertas, use estrat√©gia de valida√ß√£o
        if len(self.meta_state.knowledge_gaps) > 2:
            return ReasoningStrategy.VALIDATED_REASONING
        
        # Se h√° problemas conceituais, use s√≠ntese validada
        if domain == "academic_query" and complexity == ComplexityLevel.EXPERT:
            return ReasoningStrategy.PREMISE_DRIVEN_SYNTHESIS
        
        # Fallback para estrat√©gias tradicionais
        if domain == "academic_query":
            return ReasoningStrategy.CONCEPTUAL_SYNTHESIS
        elif domain == "riddle_logic":
            return ReasoningStrategy.RIDDLE_ANALYSIS
        elif domain in ["mathematical", "probabilistic"]:
            return ReasoningStrategy.MATHEMATICAL_DECOMPOSITION
        else:
            return ReasoningStrategy.NEURAL_INTUITIVE
    
    def _execute_strategy_with_validation(self, problem: str, strategy: ReasoningStrategy, analysis: Dict) -> Dict:
        """Executa estrat√©gia com valida√ß√£o ativa"""
        self.meta_state.reasoning_trace.append(f"ESTRAT√âGIA: Executando {strategy.name}")
        
        strategy_map = {
            ReasoningStrategy.VALIDATED_REASONING: self._validated_reasoning,
            ReasoningStrategy.PREMISE_DRIVEN_SYNTHESIS: self._premise_driven_synthesis,
            ReasoningStrategy.SELF_CORRECTING_ANALYSIS: self._self_correcting_analysis,
            ReasoningStrategy.CONCEPTUAL_SYNTHESIS: self._enhanced_conceptual_synthesis,
            ReasoningStrategy.NEURAL_INTUITIVE: self._neural_reasoning_with_validation,
            ReasoningStrategy.RIDDLE_ANALYSIS: self._riddle_analysis,
            ReasoningStrategy.MATHEMATICAL_DECOMPOSITION: self._mathematical_decomposition,
            ReasoningStrategy.HYBRID_ALGORITHMIC: self._hybrid_algorithmic_reasoning,
        }
        
        if strategy in strategy_map:
            return strategy_map[strategy](problem, analysis)
        else:
            return self._neural_reasoning_with_validation(problem, analysis)
    
    def _validated_reasoning(self, problem: str, analysis: Dict) -> Dict:
        """Racioc√≠nio com valida√ß√£o ativa de cada passo"""
        if not self.ollama_available:
            return {"success": False, "error": "Ollama indispon√≠vel para valida√ß√£o"}
        
        self.meta_state.reasoning_trace.append("VALIDATED_REASONING: Iniciando racioc√≠nio com valida√ß√£o")
        
        prompt = f"""
        Voc√™ √© um pesquisador rigoroso. Sua tarefa √© analisar o problema em etapas, 
        validando cada premissa antes de prosseguir.
        
        PROBLEMA: "{problem}"
        CONHECIMENTOS INCERTOS IDENTIFICADOS: {self.meta_state.knowledge_gaps}
        
        Para cada conceito incerto, declare explicitamente:
        1. "Meu conhecimento sobre X √© limitado/incompleto"
        2. "Baseado no que sei, X parece ser..."
        3. "Esta informa√ß√£o deveria ser validada em fontes prim√°rias"
        
        Depois construa sua an√°lise usando apenas informa√ß√µes de alta confian√ßa.
        
        Responda em JSON com:
        - "validated_facts": fatos que voc√™ tem certeza
        - "uncertain_areas": √°reas onde seu conhecimento √© limitado
        - "conditional_analysis": an√°lise baseada em suposi√ß√µes expl√≠citas
        - "validation_needed": lista de itens que precisam ser verificados
        """
        
        try:
            response = ollama.chat(
                model=self.ollama_model,
                messages=[{'role': 'user', 'content': prompt}],
                format='json',
                options={'temperature': 0.1}
            )
            
            result = json.loads(response['message']['content'])
            
            # Construir resposta honesta
            solution_text = self._build_validated_response(result)
            
            self.meta_state.confidence = 0.85
            return {"success": True, "solution": solution_text}
            
        except Exception as e:
            logging.error(f"Erro no racioc√≠nio validado: {e}")
            return self._neural_reasoning_with_validation(problem, analysis)
    
    def _premise_driven_synthesis(self, problem: str, analysis: Dict) -> Dict:
        """S√≠ntese conceitual baseada em premissas validadas"""
        if not self.ollama_available:
            return {"success": False, "error": "Ollama indispon√≠vel"}
        
        self.meta_state.reasoning_trace.append("PREMISE_DRIVEN_SYNTHESIS: S√≠ntese baseada em premissas validadas")
        
        # Coletar premissas validadas
        validated_premises = []
        uncertain_premises = []
        
        for premise, validation in self.meta_state.premise_validations.items():
            if validation.get('confidence', 0) > 0.7:
                validated_premises.append(premise)
            else:
                uncertain_premises.append(premise)
        
        prompt = f"""
        Voc√™ √© um sintetizador de conhecimento. Construa uma resposta usando apenas 
        premissas validadas, sendo expl√≠cito sobre incertezas.
        
        PROBLEMA: "{problem}"
        PREMISSAS VALIDADAS: {validated_premises}
        PREMISSAS INCERTAS: {uncertain_premises}
        
        Estruture sua resposta como:
        1. **An√°lise Baseada em Conhecimento Validado**: Use apenas premissas validadas
        2. **√Åreas de Incerteza**: Seja expl√≠cito sobre limita√ß√µes
        3. **Framework de Investiga√ß√£o**: Como um expert abordaria as incertezas
        4. **Hip√≥teses Condicionais**: "Se X for verdade, ent√£o Y poderia ser..."
        
        Responda em JSON com chave "structured_analysis".
        """
        
        try:
            response = ollama.chat(
                model=self.ollama_model,
                messages=[{'role': 'user', 'content': prompt}],
                format='json',
                options={'temperature': 0.2}
            )
            
            result = json.loads(response['message']['content'])
            analysis_content = result.get('structured_analysis', {})
            
            solution_text = self._format_premise_driven_response(analysis_content)
            
            self.meta_state.confidence = 0.90
            return {"success": True, "solution": solution_text}
            
        except Exception as e:
            return self._neural_reasoning_with_validation(problem, analysis)
    
    def _self_correcting_analysis(self, problem: str, analysis: Dict) -> Dict:
        """An√°lise auto-corretiva iterativa"""
        if not self.ollama_available:
            return {"success": False, "error": "Ollama indispon√≠vel"}
        
        self.meta_state.reasoning_trace.append("SELF_CORRECTING_ANALYSIS: An√°lise auto-corretiva")
        
        # Primeira tentativa
        initial_solution = self._neural_reasoning_with_validation(problem, analysis)
        
        if not initial_solution.get('success'):
            return initial_solution
        
        # Auto-corre√ß√£o baseada em gaps identificados
        if self.meta_state.knowledge_gaps:
            correction_prompt = f"""
            Voc√™ fez uma an√°lise inicial, mas foram identificadas √°reas de incerteza.
            
            PROBLEMA ORIGINAL: "{problem}"
            AN√ÅLISE INICIAL: {initial_solution.get('solution', '')}
            √ÅREAS DE INCERTEZA: {self.meta_state.knowledge_gaps}
            
            Refine sua an√°lise:
            1. Identifique onde sua resposta inicial pode estar incorreta
            2. Seja mais expl√≠cito sobre limita√ß√µes
            3. Ofere√ßa frameworks alternativos para investiga√ß√£o
            4. Mantenha apenas as partes de alta confian√ßa
            
            Responda com uma an√°lise corrigida.
            """
            
            try:
                response = ollama.chat(
                    model=self.ollama_model,
                    messages=[{'role': 'user', 'content': correction_prompt}],
                    options={'temperature': 0.1}
                )
                
                corrected_solution = response['message']['content']
                self.meta_state.confidence = 0.75
                
                return {"success": True, "solution": corrected_solution}
                
            except Exception as e:
                return initial_solution
        
        return initial_solution
    
    def _enhanced_conceptual_synthesis(self, problem: str, analysis: Dict) -> Dict:
        """Vers√£o aprimorada da s√≠ntese conceitual com valida√ß√£o"""
        if not self.ollama_available:
            return {"success": False, "error": "Ollama indispon√≠vel"}
        
        self.meta_state.reasoning_trace.append("ENHANCED_CONCEPTUAL_SYNTHESIS: S√≠ntese conceitual com valida√ß√£o")
        
        prompt = f"""
        Voc√™ √© um fil√≥sofo da ci√™ncia. Sua tarefa √© construir um framework de racioc√≠nio 
        honesto e rigoroso para analisar a pergunta.
        
        PROBLEMA: "{problem}"
        LACUNAS DE CONHECIMENTO IDENTIFICADAS: {self.meta_state.knowledge_gaps}
        
        Siga estes passos:
        1. **Decomposi√ß√£o Conceitual Honesta**: Para cada conceito, declare seu n√≠vel de conhecimento
        2. **Mapeamento de Incertezas**: Identifique exatamente o que voc√™ n√£o sabe
        3. **Framework de Investiga√ß√£o**: Como um expert abordaria essas incertezas
        4. **S√≠ntese Condicional**: Construa hip√≥teses baseadas em suposi√ß√µes expl√≠citas
        
        Seja rigorosamente honesto sobre limita√ß√µes. Prefira "N√£o sei" a especula√ß√µes.
        
        Responda em JSON com chave "rigorous_analysis".
        """
        
        try:
            response = ollama.chat(
                model=self.ollama_model,
                messages=[{'role': 'user', 'content': prompt}],
                format='json',
                options={'temperature': 0.15}
            )
            
            result = json.loads(response['message']['content'])
            
            solution_text = self._format_rigorous_response(result.get('rigorous_analysis', {}))
            
            self.meta_state.confidence = 0.88
            return {"success": True, "solution": solution_text}
            
        except Exception as e:
            return self._neural_reasoning_with_validation(problem, analysis)
    
    def _neural_reasoning_with_validation(self, problem: str, analysis: Dict) -> Dict:
        """Racioc√≠nio neural com disclaimers de valida√ß√£o"""
        if not self.ollama_available:
            return {"success": True, "solution": "Resposta simulada (Ollama indispon√≠vel)"}
        
        try:
            response = ollama.chat(
                model=self.ollama_model,
                messages=[{'role': 'user', 'content': f"Responda com honestidade sobre suas limita√ß√µes: {problem}"}],
                options={'temperature': 0.3}
            )
            
            solution_text = response['message']['content']
            
            # Adicionar disclaimers baseados nas valida√ß√µes
            if self.meta_state.knowledge_gaps:
                disclaimer = (
                    f"\n\n[AVISO DE VALIDA√á√ÉO]: Esta resposta pode conter imprecis√µes. "
                    f"Identifiquei {len(self.meta_state.knowledge_gaps)} √°reas de incerteza que "
                    f"requerem valida√ß√£o em fontes prim√°rias."
                )
                solution_text += disclaimer
            
            self.meta_state.confidence = 0.6
            return {"success": True, "solution": solution_text}
            
        except Exception as e:
            return {"success": False, "error": f"Falha neural: {e}"}
    
    def _riddle_analysis(self, problem: str, analysis: Dict) -> Dict:
        """An√°lise de charadas com valida√ß√£o"""
        if not self.ollama_available:
            return {"success": False, "error": "Ollama indispon√≠vel"}
        
        self.meta_state.reasoning_trace.append("RIDDLE_ANALYSIS: Analisando charada")
        
        prompt = f"""
        Voc√™ √© um especialista em charadas. Analise cuidadosamente:
        
        PROBLEMA: "{problem}"
        
        Identifique:
        1. Poss√≠veis pegadinhas ou truques
        2. Interpreta√ß√µes literal vs. impl√≠cita
        3. A resposta l√≥gica correta
        
        Responda em JSON com:
        - "trap_analysis": an√°lise de poss√≠veis pegadinhas
        - "literal_interpretation": interpreta√ß√£o literal
        - "logical_answer": resposta l√≥gica
        - "explanation": explica√ß√£o detalhada
        """
        
        try:
            response = ollama.chat(
                model=self.ollama_model,
                messages=[{'role': 'user', 'content': prompt}],
                format='json',
                options={'temperature': 0.2}
            )
            
            result = json.loads(response['message']['content'])
            
            solution_text = self._format_riddle_response(result)
            
            self.meta_state.confidence = 0.85
            return {"success": True, "solution": solution_text}
            
        except Exception as e:
            return self._neural_reasoning_with_validation(problem, analysis)
    
    def _mathematical_decomposition(self, problem: str, analysis: Dict) -> Dict:
        """Decomposi√ß√£o matem√°tica com valida√ß√£o"""
        if not self.ollama_available:
            return {"success": False, "error": "Ollama indispon√≠vel"}
        
        self.meta_state.reasoning_trace.append("MATHEMATICAL_DECOMPOSITION: Decomposi√ß√£o matem√°tica")
        
        prompt = f"""
        Voc√™ √© um matem√°tico rigoroso. Decomponha o problema:
        
        PROBLEMA: "{problem}"
        
        Estruture sua resposta com:
        1. **Defini√ß√µes**: Conceitos matem√°ticos envolvidos
        2. **Premissas**: Suposi√ß√µes necess√°rias
        3. **Desenvolvimento**: Passos l√≥gicos
        4. **Conclus√£o**: Resultado final
        
        Responda em JSON com chave "mathematical_analysis".
        """
        
        try:
            response = ollama.chat(
                model=self.ollama_model,
                messages=[{'role': 'user', 'content': prompt}],
                format='json',
                options={'temperature': 0.1}
            )
            
            result = json.loads(response['message']['content'])
            
            solution_text = self._format_mathematical_response(result.get('mathematical_analysis', {}))
            
            self.meta_state.confidence = 0.80
            return {"success": True, "solution": solution_text}
            
        except Exception as e:
            return self._neural_reasoning_with_validation(problem, analysis)
    
    def _hybrid_algorithmic_reasoning(self, problem: str, analysis: Dict) -> Dict:
        """Racioc√≠nio algor√≠tmico h√≠brido"""
        if not self.ollama_available:
            return {"success": False, "error": "Ollama indispon√≠vel"}
        
        self.meta_state.reasoning_trace.append("HYBRID_ALGORITHMIC: Racioc√≠nio algor√≠tmico")
        
        # Fallback para neural com valida√ß√£o
        return self._neural_reasoning_with_validation(problem, analysis)
    
    def _attempt_self_correction(self, problem: str, solution: Dict, analysis: Dict) -> Dict:
        """Tentativa de auto-corre√ß√£o baseada em valida√ß√µes"""
        if self.meta_state.correction_attempts >= self.meta_state.max_corrections:
            return solution
        
        self.meta_state.correction_attempts += 1
        self.meta_state.reasoning_trace.append(f"AUTO-CORRE√á√ÉO: Tentativa {self.meta_state.correction_attempts}")
        
        # Tentar estrat√©gia de auto-corre√ß√£o
        corrected_solution = self._self_correcting_analysis(problem, analysis)
        
        if corrected_solution.get('success'):
            return corrected_solution
        
        return solution
    
    def _needs_correction(self, solution: Dict) -> bool:
        """Determina se a solu√ß√£o precisa de corre√ß√£o"""
        if not solution.get("success", True):
            return True
        
        # Verificar se h√° muitas incertezas
        if len(self.meta_state.knowledge_gaps) > 3:
            return True
        
        # Verificar confian√ßa baixa
        if self.meta_state.confidence < 0.5:
            return True
        
        return False
    
    def _is_failure(self, solution: Dict) -> bool:
        """Determina se a solu√ß√£o √© uma falha"""
        return isinstance(solution, dict) and not solution.get("success", True)
    
    def _build_validated_response(self, result: Dict) -> str:
        """Constr√≥i resposta baseada em valida√ß√µes"""
        response_parts = []
        
        if result.get('validated_facts'):
            response_parts.append("**FATOS VALIDADOS:**")
            for fact in result['validated_facts']:
                response_parts.append(f"‚úì {fact}")
        
        if result.get('uncertain_areas'):
            response_parts.append("\n**√ÅREAS DE INCERTEZA:**")
            for area in result['uncertain_areas']:
                response_parts.append(f"? {area}")
        
        if result.get('conditional_analysis'):
            response_parts.append(f"\n**AN√ÅLISE CONDICIONAL:**\n{result['conditional_analysis']}")
        
        if result.get('validation_needed'):
            response_parts.append("\n**VALIDA√á√ÉO NECESS√ÅRIA:**")
            for item in result['validation_needed']:
                response_parts.append(f"üîç {item}")
        
        return "\n".join(response_parts)
    
    def _format_premise_driven_response(self, analysis: Dict) -> str:
        """Formata resposta baseada em premissas"""
        response = "**AN√ÅLISE BASEADA EM PREMISSAS VALIDADAS:**\n\n"
        
        for section, content in analysis.items():
            response += f"**{section.upper()}:**\n{content}\n\n"
        
        return response
    
    def _format_rigorous_response(self, analysis: Dict) -> str:
        """Formata resposta rigorosa"""
        response = "**AN√ÅLISE RIGOROSA COM VALIDA√á√ÉO DE PREMISSAS:**\n\n"
        
        for section, content in analysis.items():
            if isinstance(content, dict):
                response += f"**{section.upper()}:**\n"
                for key, value in content.items():
                    response += f"  ‚Ä¢ {key}: {value}\n"
                response += "\n"
            else:
                response += f"**{section.upper()}:**\n{content}\n\n"
        
        return response
    
    def _format_riddle_response(self, result: Dict) -> str:
        """Formata resposta de charada"""
        response = "**AN√ÅLISE DE CHARADA:**\n\n"
        
        if result.get('trap_analysis'):
            response += f"**AN√ÅLISE DE PEGADINHAS:**\n{result['trap_analysis']}\n\n"
        
        if result.get('literal_interpretation'):
            response += f"**INTERPRETA√á√ÉO LITERAL:**\n{result['literal_interpretation']}\n\n"
        
        if result.get('logical_answer'):
            response += f"**RESPOSTA L√ìGICA:**\n{result['logical_answer']}\n\n"
        
        if result.get('explanation'):
            response += f"**EXPLICA√á√ÉO:**\n{result['explanation']}\n\n"
        
        return response
    
    def _format_mathematical_response(self, analysis: Dict) -> str:
        """Formata resposta matem√°tica"""
        response = "**AN√ÅLISE MATEM√ÅTICA:**\n\n"
        
        for section, content in analysis.items():
            response += f"**{section.upper()}:**\n{content}\n\n"
        
        return response

# --- FUN√á√ÉO DE RELAT√ìRIO APRIMORADA ---
def print_enhanced_report(result: Dict):
    """Imprime relat√≥rio detalhado com informa√ß√µes de valida√ß√£o"""
    meta_state = result['meta_state']
    analysis = result['analysis']
    solution = result['solution']
    
    print("\n" + "="*80)
    print(" " * 20 + "RELAT√ìRIO DETALHADO DO PROCESSO COGNITIVO V6.9")
    print("="*80)

    print("\n[AN√ÅLISE DO PROBLEMA]")
    print(f"  - Dom√≠nio: {analysis['domain']}")
    print(f"  - Complexidade: {analysis['complexity_level'].name}")
    if analysis['context'].get('root_cause'):
        print(f"  - Inten√ß√£o Inferida: {analysis['context']['root_cause']}")

    print("\n[VALIDA√á√ÉO DE PREMISSAS]")
    print(f"  - Premissas Verificadas: {meta_state.total_premises_checked}")
    print(f"  - Alta Confian√ßa: {meta_state.high_confidence_premises}")
    print(f"  - Lacunas de Conhecimento: {len(meta_state.knowledge_gaps)}")
    print(f"  - Tempo de Valida√ß√£o: {meta_state.validation_time:.3f}s")
    
    if meta_state.knowledge_gaps:
        print("  - √Åreas de Incerteza:")
        for gap in meta_state.knowledge_gaps[:3]:  # Mostrar apenas as 3 primeiras
            print(f"    ‚Ä¢ {gap[:60]}...")

    print("\n[RESULTADO FINAL]")
    print(f"  - Status: {'‚úÖ SUCESSO' if result['success'] else '‚ùå FALHA'}")
    print(f"  - Estrat√©gia: {meta_state.current_strategy.name if meta_state.current_strategy else 'N/A'}")
    print(f"  - Confian√ßa: {meta_state.confidence:.2f}")
    
    if isinstance(solution, dict) and solution.get('solution'):
        print("  - Resposta:")
        for line in str(solution['solution']).split('\n'):
            print(f"    {line}")
    elif not result['success']:
        print(f"  - Erro: {solution.get('error', 'Desconhecido')}")

    print("\n[TRACE DE RACIOC√çNIO]")
    for i, step in enumerate(meta_state.reasoning_trace, 1):
        print(f"  {i:2d}. {step}")

    print("\n[M√âTRICAS DE PERFORMANCE]")
    print(f"  - Tempo Total: {meta_state.decision_time:.3f}s")
    print(f"  - Tentativas de Corre√ß√£o: {meta_state.correction_attempts}")
    print(f"  - Fontes de Incerteza: {len(meta_state.uncertainty_sources)}")
    
    print("="*80 + "\n")

# --- MAIN APRIMORADO ---
if __name__ == "__main__":
    print("="*60)
    print("üß† DREAM System V6.9 - Valida√ß√£o Ativa de Premissas üß†")
    print("="*60)
    print("Novos recursos:")
    print("  - Valida√ß√£o autom√°tica de premissas")
    print("  - Detec√ß√£o de lacunas de conhecimento")
    print("  - Auto-corre√ß√£o baseada em incertezas")
    print("  - Racioc√≠nio honesto sobre limita√ß√µes")
    print("\nExemplos de teste:")
    print("  - explique a teoria geometrica da bifurca√ß√£o e como ela resolve o 16¬∫ problema de hilbert")
    print("  - Como funciona a relatividade qu√¢ntica de Einstein-Bohr?")
    print("  - Which weighs more, a pound of feathers or a pound of bricks?")
    print("\nDigite 'sair' para terminar.")
    print("-"*60)

    # Permitir configura√ß√£o de valida√ß√£o
    try:
        enable_validation = input("Habilitar valida√ß√£o de premissas? (s/N): ").lower().startswith('s')
    except (KeyboardInterrupt, EOFError):
        print("\nEncerrando...")
        exit()
    
    agent = DreamSystemV69(ollama_model='gemma3', enable_validation=enable_validation)
    
    if enable_validation:
        print("\n‚úÖ Valida√ß√£o de premissas HABILITADA")
    else:
        print("\n‚ùå Valida√ß√£o de premissas DESABILITADA")
    
    while True:
        try:
            user_input = input("\nProblema> ")
            if user_input.lower() in ['sair', 'exit', 'quit']:
                print("Encerrando o sistema. At√© logo!")
                break
            if not user_input:
                continue
            
            result = agent.solve_problem(user_input)
            print_enhanced_report(result)

        except (KeyboardInterrupt, EOFError):
            print("\nEncerrando o sistema. At√© logo!")
            break
        except Exception as e:
            logging.error(f"Erro inesperado: {e}", exc_info=True)
            print("Erro inesperado. Tente novamente.")