{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223299c7",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "#           PROTÓTIPO DE SISTEMA NEURO-SIMBÓLICO COM META-COGNIÇÃO\n",
    "#               Inspirado pela pesquisa \"Illusion of Thinking\"\n",
    "#               Estrutura inicial para tese de mestrado\n",
    "# ==============================================================================\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. Imports e Configurações Iniciais\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "import logging\n",
    "\n",
    "# Configuração básica de logging para acompanhar o processo\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. Estruturas de Dados e Enums\n",
    "#   - Definem os \"estados mentais\" e \"estratégias\" do nosso sistema.\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class ReasoningStrategy(Enum):\n",
    "    \"\"\"Define as estratégias de raciocínio que o sistema pode adotar.\"\"\"\n",
    "    NEURAL_FAST = \"neural_fast\"          # Rápido, intuitivo, baseado em padrões\n",
    "    SYMBOLIC_CAREFUL = \"symbolic_careful\"  # Lento, deliberado, baseado em regras\n",
    "    HYBRID_BALANCED = \"hybrid_balanced\"  # Combinação dos dois, geralmente para verificação\n",
    "\n",
    "@dataclass\n",
    "class MetaCognitionState:\n",
    "    \"\"\"\n",
    "    Armazena o estado atual da \"consciência\" do sistema. É o coração da transparência.\n",
    "    Usamos `field(default_factory=list)` para evitar problemas com listas mutáveis em dataclasses.\n",
    "    \"\"\"\n",
    "    current_strategy: ReasoningStrategy = ReasoningStrategy.NEURAL_FAST\n",
    "    confidence_in_decision: float = 0.0\n",
    "    reasoning_trace: List[str] = field(default_factory=list)\n",
    "    uncertainty_sources: List[str] = field(default_factory=list)\n",
    "    context_complexity: float = 0.0\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. A Classe Principal: O Agente Meta-Cognitivo\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class NeuroSymbolicMetaCognition:\n",
    "    \"\"\"\n",
    "    Sistema que combina redes neurais (simuladas) com raciocínio simbólico (simulado)\n",
    "    e possui uma camada de meta-cognição que monitora, avalia e direciona o processo.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, neural_confidence_threshold: float = 0.75):\n",
    "        \"\"\"Inicializa o sistema com seus parâmetros e estado inicial.\"\"\"\n",
    "        self.neural_confidence_threshold = neural_confidence_threshold\n",
    "        self.symbolic_rules = self._initialize_symbolic_rules()\n",
    "        self.reset_state() # Reseta o estado para cada novo problema\n",
    "\n",
    "    def reset_state(self):\n",
    "        \"\"\"Limpa o estado meta-cognitivo para uma nova execução.\"\"\"\n",
    "        self.meta_state = MetaCognitionState()\n",
    "        logging.info(\"Estado meta-cognitivo resetado para um novo problema.\")\n",
    "\n",
    "    def _initialize_symbolic_rules(self) -> Dict:\n",
    "        \"\"\"\n",
    "        Simula a base de conhecimento de regras lógicas.\n",
    "        Em um sistema real, isso seria um motor de regras complexo.\n",
    "        \"\"\"\n",
    "        return {\n",
    "            \"mathematical\": {\n",
    "                # Esta regra agora tem um padrão regex para ser aplicada\n",
    "                \"solve_linear_equation\": r'Se x \\+ (\\d+) = (\\d+), qual é o valor de x\\?',\n",
    "                \"verify_algebraic_operations\": True\n",
    "            },\n",
    "            \"logical\": {\n",
    "                \"check_premise_conclusion_validity\": True\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def solve_problem(self, problem: str, context: Dict) -> Dict:\n",
    "        \"\"\"\n",
    "        Método principal que orquestra a resolução do problema usando o ciclo meta-cognitivo.\n",
    "        CICLO: Analisar -> Decidir Estratégia -> Executar -> Avaliar\n",
    "        \"\"\"\n",
    "        self.reset_state() # Garante que não há \"memória\" de problemas anteriores\n",
    "\n",
    "        # 1. META-ANÁLISE INICIAL: O sistema \"olha\" para o problema e para si mesmo.\n",
    "        self._meta_analyze_problem(problem, context)\n",
    "\n",
    "        # 2. ESCOLHA DA ESTRATÉGIA: Baseado na análise, decide como abordar o problema.\n",
    "        strategy = self._choose_reasoning_strategy(problem)\n",
    "\n",
    "        # 3. EXECUÇÃO DO RACIOCÍNIO: Aplica a estratégia escolhida, com monitoramento.\n",
    "        solution = self._execute_reasoning(problem, strategy)\n",
    "\n",
    "        # 4. META-AVALIAÇÃO DA SOLUÇÃO: O sistema reflete sobre o resultado e seu próprio desempenho.\n",
    "        self._meta_evaluate_solution(solution, problem)\n",
    "\n",
    "        return {\n",
    "            \"solution\": solution,\n",
    "            \"meta_state\": self.meta_state,\n",
    "        }\n",
    "\n",
    "    # ================== PASSOS DO CICLO META-COGNITIVO ==================\n",
    "\n",
    "    def _meta_analyze_problem(self, problem: str, context: Dict):\n",
    "        \"\"\"META-COGNITIVO (Passo 1): Analisa a complexidade e características do problema.\"\"\"\n",
    "        self.meta_state.reasoning_trace.append(\"META: Iniciando análise do problema.\")\n",
    "\n",
    "        # Simula a avaliação de complexidade com base em heurísticas.\n",
    "        # Em uma tese, isso seria substituído por métodos mais sofisticados.\n",
    "        complexity_factors = {\n",
    "            \"is_technical\": self._is_problem_technical(problem),\n",
    "            \"has_ambiguity\": self._detect_ambiguity(problem)\n",
    "        }\n",
    "        self.meta_state.context_complexity = np.mean(list(complexity_factors.values()))\n",
    "\n",
    "        self.meta_state.reasoning_trace.append(f\"META: Complexidade calculada: {self.meta_state.context_complexity:.2f}\")\n",
    "\n",
    "        # META-REFLEXÃO: \"Com base na complexidade, devo ser mais cauteloso?\"\n",
    "        if self.meta_state.context_complexity > 0.6:\n",
    "            self.meta_state.reasoning_trace.append(\"META: Alerta! Detectei alta complexidade. A abordagem padrão pode falhar.\")\n",
    "            self.meta_state.uncertainty_sources.append(\"high_initial_complexity\")\n",
    "\n",
    "    def _choose_reasoning_strategy(self, problem: str) -> ReasoningStrategy:\n",
    "        \"\"\"META-COGNITIVO (Passo 2): Escolhe a ferramenta certa para o trabalho.\"\"\"\n",
    "        self.meta_state.reasoning_trace.append(\"META: Decidindo a estratégia de raciocínio inicial.\")\n",
    "\n",
    "        # Regras meta-cognitivas para escolha de estratégia.\n",
    "        if \"matemática\" in problem.lower() or \"lógica\" in problem.lower() or self.meta_state.context_complexity > 0.7:\n",
    "            strategy = ReasoningStrategy.SYMBOLIC_CAREFUL\n",
    "        elif self.meta_state.context_complexity < 0.3:\n",
    "            strategy = ReasoningStrategy.NEURAL_FAST\n",
    "        else:\n",
    "            strategy = ReasoningStrategy.HYBRID_BALANCED\n",
    "\n",
    "        self.meta_state.current_strategy = strategy\n",
    "        self.meta_state.reasoning_trace.append(f\"META: Estratégia escolhida: {strategy.value}\")\n",
    "        return strategy\n",
    "\n",
    "    def _execute_reasoning(self, problem: str, strategy: ReasoningStrategy) -> str:\n",
    "        \"\"\"EXECUÇÃO (Passo 3): Aplica a estratégia de raciocínio escolhida.\"\"\"\n",
    "        if strategy == ReasoningStrategy.NEURAL_FAST:\n",
    "            return self._neural_reasoning(problem)\n",
    "        elif strategy == ReasoningStrategy.SYMBOLIC_CAREFUL:\n",
    "            return self._symbolic_reasoning(problem)\n",
    "        else: # HYBRID_BALANCED\n",
    "            return self._hybrid_reasoning(problem)\n",
    "\n",
    "    def _meta_evaluate_solution(self, solution: str, original_problem: str):\n",
    "        \"\"\"META-AVALIAÇÃO (Passo 4): Reflexão final sobre a qualidade da solução e do processo.\"\"\"\n",
    "        self.meta_state.reasoning_trace.append(\"META: Iniciando avaliação final da solução e do processo.\")\n",
    "\n",
    "        # Meta-perguntas que o sistema faz a si mesmo:\n",
    "        if len(self.meta_state.uncertainty_sources) > 0:\n",
    "            self.meta_state.reasoning_trace.append(f\"META: REFLEXÃO: O processo teve fontes de incerteza ({self.meta_state.uncertainty_sources}). A confiança deve ser ajustada.\")\n",
    "            # Ajuste de confiança baseado na autoavaliação\n",
    "            self.meta_state.confidence_in_decision *= (1.0 - 0.2 * len(self.meta_state.uncertainty_sources))\n",
    "            self.meta_state.reasoning_trace.append(f\"META: Confiança final ajustada para: {self.meta_state.confidence_in_decision:.2f}\")\n",
    "        else:\n",
    "            self.meta_state.reasoning_trace.append(\"META: REFLEXÃO: O processo de raciocínio foi limpo, sem fontes de incerteza detectadas.\")\n",
    "\n",
    "    # ================== MÓDULOS DE RACIOCÍNIO (SIMULADOS) ==================\n",
    "\n",
    "    def _neural_reasoning(self, problem: str) -> str:\n",
    "        \"\"\"Simula o raciocínio neural (Sistema 1): rápido e baseado em padrões.\"\"\"\n",
    "        self.meta_state.reasoning_trace.append(\"NEURAL: Iniciando processamento rápido baseado em padrões.\")\n",
    "        \n",
    "        # Simulação: um LLM real poderia dar uma resposta direta, mas talvez errada.\n",
    "        # Aqui, vamos simular uma resposta \"intuitiva\".\n",
    "        if \"x +\" in problem:\n",
    "            # Uma resposta intuitiva, mas possivelmente incompleta/mal formatada.\n",
    "            solution = \"A resposta é 3.\"\n",
    "            neural_confidence = 0.9 # Simula alta confiança da rede\n",
    "        else:\n",
    "            solution = f\"Resposta intuitiva para '{problem}'.\"\n",
    "            neural_confidence = 0.6\n",
    "\n",
    "        self.meta_state.reasoning_trace.append(f\"NEURAL: Resposta gerada com confiança de {neural_confidence:.2f}\")\n",
    "        self.meta_state.confidence_in_decision = neural_confidence\n",
    "        \n",
    "        # META-MONITORAMENTO: \"Esta confiança é suficiente?\"\n",
    "        if neural_confidence < self.neural_confidence_threshold:\n",
    "            self.meta_state.reasoning_trace.append(f\"META: Alerta! Confiança neural ({neural_confidence:.2f}) abaixo do limiar ({self.neural_confidence_threshold}).\")\n",
    "            self.meta_state.uncertainty_sources.append(\"low_neural_confidence\")\n",
    "            # Este é um ponto chave: o sistema pode decidir aqui mesmo mudar de estratégia,\n",
    "            # mas no nosso fluxo atual, a avaliação ocorre depois. Uma melhoria seria um ciclo mais dinâmico.\n",
    "            \n",
    "        return solution\n",
    "\n",
    "    def _symbolic_reasoning(self, problem: str) -> str:\n",
    "        \"\"\"Simula o raciocínio simbólico (Sistema 2): lógico e passo a passo.\"\"\"\n",
    "        self.meta_state.reasoning_trace.append(\"SYMBOLIC: Iniciando raciocínio baseado em regras.\")\n",
    "        \n",
    "        # Tenta aplicar a regra de equação linear\n",
    "        rule = self.symbolic_rules[\"mathematical\"][\"solve_linear_equation\"]\n",
    "        match = re.search(rule, problem)\n",
    "\n",
    "        if match:\n",
    "            self.meta_state.reasoning_trace.append(\"SYMBOLIC: Regra 'solve_linear_equation' aplicada com sucesso.\")\n",
    "            a = int(match.group(1))\n",
    "            b = int(match.group(2))\n",
    "            \n",
    "            # Geração do passo a passo (aqui está a transparência)\n",
    "            step1 = f\"Equação identificada: x + {a} = {b}\"\n",
    "            step2 = f\"Subtrair {a} de ambos os lados: x = {b} - {a}\"\n",
    "            result = b - a\n",
    "            step3 = f\"Solução: x = {result}\"\n",
    "            \n",
    "            # Adiciona os passos ao trace\n",
    "            self.meta_state.reasoning_trace.append(f\"SYMBOLIC (Passo 1): {step1}\")\n",
    "            self.meta_state.reasoning_trace.append(f\"SYMBOLIC (Passo 2): {step2}\")\n",
    "            self.meta_state.reasoning_trace.append(f\"SYMBOLIC (Passo 3): {step3}\")\n",
    "            \n",
    "            self.meta_state.confidence_in_decision = 0.98 # Alta confiança, pois o processo é determinístico\n",
    "            return f\"O valor de x é {result}.\"\n",
    "        else:\n",
    "            self.meta_state.reasoning_trace.append(\"SYMBOLIC: Nenhuma regra aplicável encontrada para o problema.\")\n",
    "            self.meta_state.uncertainty_sources.append(\"no_symbolic_rule_matched\")\n",
    "            self.meta_state.confidence_in_decision = 0.1\n",
    "            return \"Não foi possível resolver o problema com as regras simbólicas atuais.\"\n",
    "\n",
    "    def _hybrid_reasoning(self, problem: str) -> str:\n",
    "        \"\"\"Simula o raciocínio híbrido: usa um para gerar, outro para verificar.\"\"\"\n",
    "        self.meta_state.reasoning_trace.append(\"HYBRID: Iniciando coordenação entre módulos neural e simbólico.\")\n",
    "\n",
    "        # Salva o estado atual para restaurar depois\n",
    "        original_confidence = self.meta_state.confidence_in_decision\n",
    "        original_uncertainties = self.meta_state.uncertainty_sources.copy()\n",
    "\n",
    "        # 1. Obter uma resposta rápida do módulo neural\n",
    "        neural_solution = self._neural_reasoning(problem)\n",
    "        neural_confidence = self.meta_state.confidence_in_decision\n",
    "        neural_uncertainties = self.meta_state.uncertainty_sources.copy()\n",
    "        \n",
    "        self.meta_state.reasoning_trace.append(f\"HYBRID (Neural): Proposta inicial -> '{neural_solution}'\")\n",
    "\n",
    "        # Reseta para análise simbólica\n",
    "        self.meta_state.confidence_in_decision = 0.0\n",
    "        self.meta_state.uncertainty_sources = original_uncertainties.copy()\n",
    "\n",
    "        # 2. Usar o módulo simbólico para validar ou refazer\n",
    "        symbolic_solution = self._symbolic_reasoning(problem)\n",
    "        symbolic_confidence = self.meta_state.confidence_in_decision\n",
    "        \n",
    "        self.meta_state.reasoning_trace.append(f\"HYBRID (Simbólico): Verificação/Solução -> '{symbolic_solution}'\")\n",
    "\n",
    "        # META-COORDENAÇÃO: \"Os dois sistemas concordam?\"\n",
    "        # Simulação simples de concordância: extrair números das respostas\n",
    "        num_neural = re.findall(r'\\d+', neural_solution)\n",
    "        num_symbolic = re.findall(r'\\d+', symbolic_solution)\n",
    "\n",
    "        if num_neural and num_symbolic and num_neural[0] == num_symbolic[0]:\n",
    "            self.meta_state.reasoning_trace.append(\"META: Concordância entre neural e simbólico. Aumentando a confiança.\")\n",
    "            self.meta_state.confidence_in_decision = 0.99\n",
    "            return symbolic_solution # Retorna a solução simbólica, mais bem estruturada\n",
    "        else:\n",
    "            self.meta_state.reasoning_trace.append(\"META: Alerta! Discordância detectada entre as respostas neural e simbólica.\")\n",
    "            self.meta_state.uncertainty_sources.append(\"neural_symbolic_disagreement\")\n",
    "            self.meta_state.confidence_in_decision = 0.3\n",
    "            return f\"Conflito de respostas. Neural: '{neural_solution}', Simbólica: '{symbolic_solution}'\"\n",
    "\n",
    "    # ================== MÉTODOS AUXILIARES (SENSORES) ==================\n",
    "\n",
    "    def _is_problem_technical(self, text: str) -> float:\n",
    "        \"\"\"Avalia se o texto contém jargão técnico.\"\"\"\n",
    "        technical_indicators = [\"matemática\", \"equação\", \"lógica\", \"derivada\", \"integral\", \"algoritmo\"]\n",
    "        score = sum(1 for term in technical_indicators if term in text.lower())\n",
    "        return min(1.0, score / 2.0) # Normaliza a pontuação\n",
    "\n",
    "    def _detect_ambiguity(self, text: str) -> float:\n",
    "        \"\"\"Avalia se o texto contém palavras que indicam ambiguidade.\"\"\"\n",
    "        ambiguous_words = [\"pode\", \"talvez\", \"possivelmente\", \"geralmente\", \"acho que\"]\n",
    "        score = sum(1 for word in ambiguous_words if word in text.lower())\n",
    "        return min(1.0, score / 2.0) # Normaliza\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. Exemplo de Uso\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "def run_simulation(problem_statement, context_info):\n",
    "    \"\"\"Função para rodar e imprimir uma simulação completa.\"\"\"\n",
    "    print(\"=\"*50)\n",
    "    print(f\"PROBLEMA: '{problem_statement}'\")\n",
    "    print(f\"CONTEXTO: {context_info}\")\n",
    "    print(\"-\"*50)\n",
    "\n",
    "    system = NeuroSymbolicMetaCognition()\n",
    "    result = system.solve_problem(problem_statement, context_info)\n",
    "    meta_state = result['meta_state']\n",
    "\n",
    "    print(\"\\n=== RESULTADO FINAL ===\")\n",
    "    print(f\"Solução Proposta: {result['solution']}\")\n",
    "    print(f\"Confiança Final: {meta_state.confidence_in_decision:.2f}\")\n",
    "    print(f\"Estratégia Dominante: {meta_state.current_strategy.value}\")\n",
    "\n",
    "    print(\"\\n=== TRACE DE RACIOCÍNIO META-COGNITIVO (Transparência Real) ===\")\n",
    "    for i, step in enumerate(meta_state.reasoning_trace, 1):\n",
    "        print(f\"{i}. {step}\")\n",
    "\n",
    "    print(\"\\n=== FONTES DE INCERTEZA IDENTIFICADAS ===\")\n",
    "    if meta_state.uncertainty_sources:\n",
    "        for source in meta_state.uncertainty_sources:\n",
    "            print(f\"- {source}\")\n",
    "    else:\n",
    "        print(\"Nenhuma fonte de incerteza foi registrada.\")\n",
    "    print(\"=\"*50 + \"\\n\")\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Cenário 1: Problema matemático claro -> Deve escolher a estratégia simbólica\n",
    "    problem1 = \"Em uma aula de matemática, a professora pergunta: Se x + 2 = 5, qual é o valor de x?\"\n",
    "    context1 = {\"domain\": \"matemática\", \"source\": \"livro didático\"}\n",
    "    run_simulation(problem1, context1)\n",
    "\n",
    "    # Cenário 2: Problema ambíguo e aberto -> Deve usar neural ou híbrido e ter baixa confiança\n",
    "    problem2 = \"Qual você acha que é o sentido da vida?\"\n",
    "    context2 = {\"domain\": \"filosofia\", \"urgency\": \"baixa\"}\n",
    "    run_simulation(problem2, context2)\n",
    "    \n",
    "    # Cenário 3: Problema que pode ser resolvido pelos dois, forçando o modo híbrido\n",
    "    problem3 = \"Eu acho que em matemática, se x + 8 = 15, x talvez seja 7. Está certo?\"\n",
    "    context3 = {\"domain\": \"verificação\", \"source\": \"aluno incerto\"}\n",
    "    run_simulation(problem3, context3)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
