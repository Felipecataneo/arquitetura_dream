{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994c320e",
   "metadata": {
    "vscode": {
     "languageId": "plaintext"
    }
   },
   "outputs": [],
   "source": [
    "# ==============================================================================\n",
    "#           PROTÓTIPO V2: SISTEMA NEURO-SIMBÓLICO COM META-COGNIÇÃO\n",
    "#               Implementando Re-estratégia Dinâmica e Regras Flexíveis\n",
    "# ==============================================================================\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 1. Imports e Configurações (sem alterações)\n",
    "# ------------------------------------------------------------------------------\n",
    "import numpy as np\n",
    "import re\n",
    "from typing import Dict, List, Tuple, Optional\n",
    "from dataclasses import dataclass, field\n",
    "from enum import Enum\n",
    "import logging\n",
    "\n",
    "logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 2. Estruturas de Dados e Enums (sem alterações)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class ReasoningStrategy(Enum):\n",
    "    NEURAL_FAST = \"neural_fast\"\n",
    "    SYMBOLIC_CAREFUL = \"symbolic_careful\"\n",
    "    HYBRID_BALANCED = \"hybrid_balanced\"\n",
    "\n",
    "@dataclass\n",
    "class MetaCognitionState:\n",
    "    current_strategy: ReasoningStrategy = ReasoningStrategy.NEURAL_FAST\n",
    "    confidence_in_decision: float = 0.0\n",
    "    reasoning_trace: List[str] = field(default_factory=list)\n",
    "    uncertainty_sources: List[str] = field(default_factory=list)\n",
    "    context_complexity: float = 0.0\n",
    "    attempted_strategies: List[ReasoningStrategy] = field(default_factory=list) # ### MELHORIA ###: Rastreia estratégias já tentadas\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 3. A Classe Principal: O Agente Meta-Cognitivo (com modificações)\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "class NeuroSymbolicMetaCognition:\n",
    "    def __init__(self, neural_confidence_threshold: float = 0.75):\n",
    "        self.neural_confidence_threshold = neural_confidence_threshold\n",
    "        self.symbolic_rules = self._initialize_symbolic_rules()\n",
    "        self.reset_state()\n",
    "\n",
    "    def reset_state(self):\n",
    "        self.meta_state = MetaCognitionState()\n",
    "        logging.info(\"Estado meta-cognitivo resetado para um novo problema.\")\n",
    "\n",
    "    def _initialize_symbolic_rules(self) -> Dict:\n",
    "        \"\"\" ### MELHORIA 1: Regras Simbólicas Mais Flexíveis ### \"\"\"\n",
    "        return {\n",
    "            \"mathematical\": {\n",
    "                # REGRA ANTIGA (muito rígida): r'Se x \\+ (\\d+) = (\\d+), qual é o valor de x\\?'\n",
    "                # REGRA NOVA (flexível): Busca pelo padrão 'x + num = num' em qualquer lugar do texto.\n",
    "                # \\s* permite espaços variáveis. (?i) torna a busca case-insensitive.\n",
    "                \"extract_linear_equation\": r'(?i)x\\s*\\+\\s*(\\d+)\\s*=\\s*(\\d+)'\n",
    "            },\n",
    "            \"logical\": {\n",
    "                \"check_premise_conclusion_validity\": True\n",
    "            }\n",
    "        }\n",
    "\n",
    "    def solve_problem(self, problem: str, context: Dict) -> Dict:\n",
    "        self.reset_state()\n",
    "        self._meta_analyze_problem(problem, context)\n",
    "\n",
    "        # O ciclo de execução agora é dinâmico e pode mudar de estratégia\n",
    "        solution = self._execute_reasoning_cycle(problem)\n",
    "\n",
    "        self._meta_evaluate_solution(solution, problem)\n",
    "\n",
    "        return {\"solution\": solution, \"meta_state\": self.meta_state}\n",
    "\n",
    "    def _meta_analyze_problem(self, problem: str, context: Dict):\n",
    "        self.meta_state.reasoning_trace.append(\"META: Iniciando análise do problema.\")\n",
    "        complexity_factors = {\n",
    "            \"is_technical\": self._is_problem_technical(problem),\n",
    "            \"has_ambiguity\": self._detect_ambiguity(problem)\n",
    "        }\n",
    "        self.meta_state.context_complexity = np.mean(list(complexity_factors.values()))\n",
    "        self.meta_state.reasoning_trace.append(f\"META: Complexidade calculada: {self.meta_state.context_complexity:.2f}\")\n",
    "        if self.meta_state.context_complexity > 0.6:\n",
    "            self.meta_state.reasoning_trace.append(\"META: Alerta! Detectei alta complexidade. A abordagem padrão pode falhar.\")\n",
    "            self.meta_state.uncertainty_sources.append(\"high_initial_complexity\")\n",
    "\n",
    "    def _choose_initial_strategy(self, problem: str) -> ReasoningStrategy:\n",
    "        \"\"\"Escolhe a *primeira* estratégia a ser tentada.\"\"\"\n",
    "        self.meta_state.reasoning_trace.append(\"META: Decidindo a estratégia de raciocínio *inicial*.\")\n",
    "\n",
    "        # A lógica de escolha inicial permanece, mas agora é apenas um ponto de partida.\n",
    "        if \"matemática\" in problem.lower() or \"equação\" in problem.lower() or self.meta_state.context_complexity > 0.7:\n",
    "             # Prioriza o simbólico para problemas que parecem técnicos\n",
    "            strategy = ReasoningStrategy.SYMBOLIC_CAREFUL\n",
    "        elif self.meta_state.context_complexity < 0.3:\n",
    "            strategy = ReasoningStrategy.NEURAL_FAST\n",
    "        else:\n",
    "            strategy = ReasoningStrategy.HYBRID_BALANCED\n",
    "\n",
    "        self.meta_state.reasoning_trace.append(f\"META: Estratégia inicial escolhida: {strategy.value}\")\n",
    "        return strategy\n",
    "\n",
    "    def _execute_reasoning_cycle(self, problem: str) -> str:\n",
    "        \"\"\"\n",
    "        ### MELHORIA 2 & 3: Ciclo de Re-estratégia Dinâmica ###\n",
    "        Executa, avalia e, se necessário, tenta uma nova estratégia (fallback).\n",
    "        \"\"\"\n",
    "        initial_strategy = self._choose_initial_strategy(problem)\n",
    "        self.meta_state.current_strategy = initial_strategy\n",
    "\n",
    "        max_retries = 2\n",
    "        for attempt in range(max_retries):\n",
    "            # Adiciona a estratégia atual à lista de tentativas\n",
    "            self.meta_state.attempted_strategies.append(self.meta_state.current_strategy)\n",
    "\n",
    "            # Executa a estratégia atual\n",
    "            strategy = self.meta_state.current_strategy\n",
    "            if strategy == ReasoningStrategy.NEURAL_FAST:\n",
    "                solution = self._neural_reasoning(problem)\n",
    "            elif strategy == ReasoningStrategy.SYMBOLIC_CAREFUL:\n",
    "                solution = self._symbolic_reasoning(problem)\n",
    "            else: # HYBRID_BALANCED\n",
    "                solution = self._hybrid_reasoning(problem)\n",
    "\n",
    "            # Avalia se a estratégia falhou e se uma nova tentativa é necessária\n",
    "            if self._should_retry(attempt, max_retries):\n",
    "                # Se a estratégia falhou, o sistema decide qual será a próxima\n",
    "                new_strategy = self._re_strategize()\n",
    "                if new_strategy:\n",
    "                    self.meta_state.current_strategy = new_strategy\n",
    "                else:\n",
    "                    # Nenhuma outra estratégia para tentar, encerra o ciclo\n",
    "                    break\n",
    "            else:\n",
    "                # A estratégia foi bem-sucedida ou não há mais tentativas, encerra o ciclo\n",
    "                return solution\n",
    "\n",
    "        return solution # Retorna a solução da última tentativa\n",
    "\n",
    "    def _should_retry(self, attempt, max_retries):\n",
    "        \"\"\"META-COGNITIVO: Avalia se o resultado da estratégia atual é inaceitável e se deve tentar de novo.\"\"\"\n",
    "        if attempt + 1 >= max_retries:\n",
    "            return False # Esgotou as tentativas\n",
    "\n",
    "        # Condições de falha que disparam uma nova tentativa\n",
    "        if \"no_symbolic_rule_matched\" in self.meta_state.uncertainty_sources:\n",
    "            return True\n",
    "        # Poderíamos adicionar mais condições aqui, ex: confiança muito baixa\n",
    "\n",
    "        return False\n",
    "\n",
    "    def _re_strategize(self) -> Optional[ReasoningStrategy]:\n",
    "        \"\"\"META-COGNITIVO: Escolhe uma nova estratégia de fallback.\"\"\"\n",
    "        self.meta_state.reasoning_trace.append(f\"META: A estratégia '{self.meta_state.current_strategy.value}' falhou. Re-avaliando...\")\n",
    "\n",
    "        # Regras de Fallback\n",
    "        # Se a simbólica falhou, a melhor aposta é a híbrida, que pode usar o neural para entender e o simbólico para validar.\n",
    "        if self.meta_state.current_strategy == ReasoningStrategy.SYMBOLIC_CAREFUL and ReasoningStrategy.HYBRID_BALANCED not in self.meta_state.attempted_strategies:\n",
    "            self.meta_state.reasoning_trace.append(\"META: Fallback -> Tentando a estratégia HÍBRIDA.\")\n",
    "            return ReasoningStrategy.HYBRID_BALANCED\n",
    "\n",
    "        # Se a neural teve baixa confiança, a híbrida é a melhor para verificação.\n",
    "        if self.meta_state.current_strategy == ReasoningStrategy.NEURAL_FAST and ReasoningStrategy.HYBRID_BALANCED not in self.meta_state.attempted_strategies:\n",
    "            self.meta_state.reasoning_trace.append(\"META: Fallback -> Tentando a estratégia HÍBRIDA para verificação.\")\n",
    "            return ReasoningStrategy.HYBRID_BALANCED\n",
    "\n",
    "        self.meta_state.reasoning_trace.append(\"META: Nenhuma estratégia de fallback disponível. Encerrando ciclo de tentativas.\")\n",
    "        return None # Nenhuma nova estratégia para tentar\n",
    "\n",
    "\n",
    "    def _meta_evaluate_solution(self, solution: str, original_problem: str):\n",
    "        # A lógica aqui permanece a mesma, mas agora ela opera sobre o resultado final do ciclo.\n",
    "        self.meta_state.reasoning_trace.append(\"META: Iniciando avaliação final da solução e do processo.\")\n",
    "        if len(self.meta_state.uncertainty_sources) > 0:\n",
    "            self.meta_state.reasoning_trace.append(f\"META: REFLEXÃO: O processo teve fontes de incerteza ({self.meta_state.uncertainty_sources}). A confiança deve ser ajustada.\")\n",
    "            self.meta_state.confidence_in_decision *= (1.0 - 0.2 * len(self.meta_state.uncertainty_sources))\n",
    "            self.meta_state.reasoning_trace.append(f\"META: Confiança final ajustada para: {self.meta_state.confidence_in_decision:.2f}\")\n",
    "        else:\n",
    "            self.meta_state.reasoning_trace.append(\"META: REFLEXÃO: O processo de raciocínio foi limpo, sem fontes de incerteza detectadas.\")\n",
    "\n",
    "    def _neural_reasoning(self, problem: str) -> str:\n",
    "        self.meta_state.reasoning_trace.append(\"NEURAL: Iniciando processamento rápido baseado em padrões.\")\n",
    "\n",
    "        # ### MELHORIA ###: Simulação um pouco mais inteligente para extrair o número\n",
    "        match = re.search(r'(\\d+)\\s*\\.\\s*Está certo\\?', problem)\n",
    "        if match:\n",
    "            # Simula a resposta a uma pergunta de verificação\n",
    "            solution = f\"Sim, a resposta parece ser {match.group(1)}.\"\n",
    "            neural_confidence = 0.85\n",
    "        elif \"x +\" in problem:\n",
    "            # Simula uma resposta intuitiva, mas possivelmente incompleta\n",
    "            nums = re.findall(r'\\d+', problem)\n",
    "            if len(nums) == 2:\n",
    "                solution = f\"A resposta é {int(nums[1]) - int(nums[0])}.\"\n",
    "            else:\n",
    "                solution = \"A resposta é 3.\" # Fallback genérico\n",
    "            neural_confidence = 0.90\n",
    "        else:\n",
    "            solution = f\"Resposta intuitiva para '{problem}'.\"\n",
    "            neural_confidence = 0.60\n",
    "\n",
    "        self.meta_state.reasoning_trace.append(f\"NEURAL: Resposta gerada com confiança de {neural_confidence:.2f}\")\n",
    "        self.meta_state.confidence_in_decision = neural_confidence\n",
    "        if neural_confidence < self.neural_confidence_threshold:\n",
    "            self.meta_state.reasoning_trace.append(f\"META: Alerta! Confiança neural ({neural_confidence:.2f}) abaixo do limiar ({self.neural_confidence_threshold}).\")\n",
    "            self.meta_state.uncertainty_sources.append(\"low_neural_confidence\")\n",
    "        return solution\n",
    "\n",
    "    def _symbolic_reasoning(self, problem: str) -> str:\n",
    "        \"\"\"Usa a nova regra flexível.\"\"\"\n",
    "        self.meta_state.reasoning_trace.append(\"SYMBOLIC: Iniciando raciocínio baseado em regras flexíveis.\")\n",
    "\n",
    "        rule = self.symbolic_rules[\"mathematical\"][\"extract_linear_equation\"]\n",
    "        match = re.search(rule, problem)\n",
    "\n",
    "        if match:\n",
    "            # Limpa incertezas anteriores se encontrou uma regra\n",
    "            if \"no_symbolic_rule_matched\" in self.meta_state.uncertainty_sources:\n",
    "                self.meta_state.uncertainty_sources.remove(\"no_symbolic_rule_matched\")\n",
    "\n",
    "            self.meta_state.reasoning_trace.append(\"SYMBOLIC: Regra 'extract_linear_equation' aplicada com sucesso.\")\n",
    "            a = int(match.group(1))\n",
    "            b = int(match.group(2))\n",
    "\n",
    "            step1 = f\"Equação extraída: x + {a} = {b}\"\n",
    "            step2 = f\"Subtraindo {a} de ambos os lados: x = {b} - {a}\"\n",
    "            result = b - a\n",
    "            step3 = f\"Solução: x = {result}\"\n",
    "\n",
    "            self.meta_state.reasoning_trace.extend([f\"SYMBOLIC (Passo 1): {step1}\", f\"SYMBOLIC (Passo 2): {step2}\", f\"SYMBOLIC (Passo 3): {step3}\"])\n",
    "\n",
    "            self.meta_state.confidence_in_decision = 0.98\n",
    "            return f\"O valor de x é {result}.\"\n",
    "        else:\n",
    "            self.meta_state.reasoning_trace.append(\"SYMBOLIC: Nenhuma regra matemática aplicável encontrada no texto.\")\n",
    "            if \"no_symbolic_rule_matched\" not in self.meta_state.uncertainty_sources:\n",
    "                 self.meta_state.uncertainty_sources.append(\"no_symbolic_rule_matched\")\n",
    "            self.meta_state.confidence_in_decision = 0.1\n",
    "            return \"Não foi possível resolver o problema com as regras simbólicas atuais.\"\n",
    "\n",
    "    def _hybrid_reasoning(self, problem: str) -> str:\n",
    "        # A lógica interna do Híbrido pode ser simplificada, pois o ciclo externo agora gerencia os fallbacks.\n",
    "        # Ele age como um \"consultor especialista\" que usa ambos os métodos e reporta.\n",
    "        self.meta_state.reasoning_trace.append(\"HYBRID: Iniciando coordenação entre módulos neural e simbólico.\")\n",
    "\n",
    "        # Executa ambos os módulos para comparação\n",
    "        neural_solution = self._neural_reasoning(problem)\n",
    "        symbolic_solution = self._symbolic_reasoning(problem)\n",
    "\n",
    "        # Compara os resultados\n",
    "        num_neural = re.findall(r'\\d+', neural_solution)\n",
    "        num_symbolic = re.findall(r'\\d+', symbolic_solution)\n",
    "\n",
    "        if num_neural and num_symbolic and num_neural[-1] == num_symbolic[-1]:\n",
    "            self.meta_state.reasoning_trace.append(\"META: Concordância entre neural e simbólico. Confiança alta.\")\n",
    "            self.meta_state.confidence_in_decision = 0.99\n",
    "            # Remove incerteza de discordância se ela foi adicionada por engano\n",
    "            if \"neural_symbolic_disagreement\" in self.meta_state.uncertainty_sources:\n",
    "                self.meta_state.uncertainty_sources.remove(\"neural_symbolic_disagreement\")\n",
    "            return symbolic_solution # Retorna a solução simbólica, que é mais estruturada\n",
    "        else:\n",
    "            self.meta_state.reasoning_trace.append(\"META: Alerta! Discordância detectada.\")\n",
    "            if \"neural_symbolic_disagreement\" not in self.meta_state.uncertainty_sources:\n",
    "                self.meta_state.uncertainty_sources.append(\"neural_symbolic_disagreement\")\n",
    "            self.meta_state.confidence_in_decision = 0.3\n",
    "            return f\"Conflito de respostas. Neural: '{neural_solution}', Simbólica: '{symbolic_solution}'\"\n",
    "\n",
    "\n",
    "    def _is_problem_technical(self, text: str) -> float:\n",
    "        technical_indicators = [\"matemática\", \"equação\", \"lógica\", \"derivada\", \"integral\", \"algoritmo\"]\n",
    "        score = sum(1 for term in technical_indicators if term in text.lower())\n",
    "        return min(1.0, score / 2.0)\n",
    "\n",
    "    def _detect_ambiguity(self, text: str) -> float:\n",
    "        ambiguous_words = [\"pode\", \"talvez\", \"possivelmente\", \"geralmente\", \"acho que\"]\n",
    "        score = sum(1 for word in ambiguous_words if word in text.lower())\n",
    "        return min(1.0, score / 2.0)\n",
    "\n",
    "# ------------------------------------------------------------------------------\n",
    "# 4. Exemplo de Uso (com um novo cenário para testar o fallback)\n",
    "# ------------------------------------------------------------------------------\n",
    "def run_simulation(problem_statement, context_info):\n",
    "    print(\"=\"*60)\n",
    "    print(f\"PROBLEMA: '{problem_statement}'\")\n",
    "    print(f\"CONTEXTO: {context_info}\")\n",
    "    print(\"-\"*60)\n",
    "    system = NeuroSymbolicMetaCognition()\n",
    "    result = system.solve_problem(problem_statement, context_info)\n",
    "    meta_state = result['meta_state']\n",
    "    print(\"\\n=== RESULTADO FINAL ===\")\n",
    "    print(f\"Solução Proposta: {result['solution']}\")\n",
    "    print(f\"Confiança Final: {meta_state.confidence_in_decision:.2f}\")\n",
    "    print(f\"Estratégia(s) Tentada(s): {[s.value for s in meta_state.attempted_strategies]}\")\n",
    "    print(\"\\n=== TRACE DE RACIOCÍNIO META-COGNITIVO (Transparência Real) ===\")\n",
    "    for i, step in enumerate(meta_state.reasoning_trace, 1):\n",
    "        print(f\"{i}. {step}\")\n",
    "    print(\"\\n=== FONTES DE INCERTEZA IDENTIFICADAS ===\")\n",
    "    if meta_state.uncertainty_sources:\n",
    "        for source in meta_state.uncertainty_sources:\n",
    "            print(f\"- {source}\")\n",
    "    else:\n",
    "        print(\"Nenhuma fonte de incerteza foi registrada.\")\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Cenário 1: Problema matemático claro (deve funcionar como antes)\n",
    "    problem1 = \"Em uma aula de matemática, a professora pergunta: Se x + 2 = 5, qual é o valor de x?\"\n",
    "    context1 = {\"domain\": \"matemática\", \"source\": \"livro didático\"}\n",
    "    run_simulation(problem1, context1)\n",
    "\n",
    "    # Cenário 2: Problema filosófico (deve funcionar como antes)\n",
    "    problem2 = \"Qual você acha que é o sentido da vida?\"\n",
    "    context2 = {\"domain\": \"filosofia\", \"urgency\": \"baixa\"}\n",
    "    run_simulation(problem2, context2)\n",
    "\n",
    "    # Cenário 3: O PROBLEMA QUE FALHOU ANTES (agora deve funcionar na primeira tentativa)\n",
    "    problem3 = \"Eu acho que em matemática, se x + 8 = 15, x talvez seja 7. Está certo?\"\n",
    "    context3 = {\"domain\": \"verificação\", \"source\": \"aluno incerto\"}\n",
    "    run_simulation(problem3, context3)\n",
    "\n",
    "    # Cenário 4: NOVO PROBLEMA PARA FORÇAR O FALLBACK\n",
    "    # A regra simbólica não sabe o que é 'y'. Isso forçará um erro e a re-estratégia.\n",
    "    problem4 = \"Em lógica, se y + 10 = 22, o que é y?\"\n",
    "    context4 = {\"domain\": \"lógica\", \"source\": \"quebra-cabeça\"}\n",
    "    run_simulation(problem4, context4)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
